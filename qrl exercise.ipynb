{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc7e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Action 0, Success 0.140, Policy [0.5 0.5]\n",
      "Episode 2: Action 0, Success 0.125, Policy [0.5 0.5]\n",
      "Episode 3: Action 0, Success 0.144, Policy [0.5 0.5]\n",
      "Episode 4: Action 0, Success 0.154, Policy [0.5 0.5]\n",
      "Episode 5: Action 1, Success 0.138, Policy [0.5 0.5]\n",
      "Episode 6: Action 1, Success 0.163, Policy [0.5 0.5]\n",
      "Episode 7: Action 0, Success 0.164, Policy [0.5 0.5]\n",
      "Episode 8: Action 1, Success 0.152, Policy [0.5 0.5]\n",
      "Episode 9: Action 1, Success 0.141, Policy [0.5 0.5]\n",
      "Episode 10: Action 0, Success 0.175, Policy [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "class QuantumAgent:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.policy = np.array([0.5, 0.5])  # Equal probability for actions\n",
    "    \n",
    "    def select_action(self):\n",
    "        return np.random.choice([0, 1], p=self.policy)\n",
    "    \n",
    "    def update_policy(self, success):\n",
    "        # Grover-inspired update\n",
    "        grover_update = 2 * success - 1  # +1 if success, -1 if failure\n",
    "        self.policy += self.learning_rate * grover_update\n",
    "        self.policy = np.clip(self.policy, 0, 1)\n",
    "        self.policy /= np.sum(self.policy)  # Normalize\n",
    "    \n",
    "    def generate_quantum_circuit(self, action):\n",
    "        qc = QuantumCircuit(1, 1)\n",
    "        if action == 0:\n",
    "            qc.rx(np.pi / 4, 0)\n",
    "        else:\n",
    "            qc.ry(np.pi / 4, 0)\n",
    "        qc.measure(0, 0)\n",
    "        return qc\n",
    "    \n",
    "    def train(self, episodes=10):\n",
    "        simulator = Aer.get_backend('qasm_simulator')\n",
    "        for episode in range(episodes):\n",
    "            action = self.select_action()\n",
    "            qc = self.generate_quantum_circuit(action)\n",
    "            result = simulator.run(qc).result()\n",
    "            counts = result.get_counts()\n",
    "            success = counts.get('1', 0) / 1000  # Measure probability of |1>\n",
    "            self.update_policy(success)\n",
    "            print(f\"Episode {episode + 1}: Action {action}, Success {success:.3f}, Policy {self.policy}\")\n",
    "\n",
    "# Run the agent\n",
    "agent = QuantumAgent()\n",
    "agent.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f79f7-9b0a-48f9-a95e-e51d0eeee095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiskit_env)",
   "language": "python",
   "name": "qiskit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
